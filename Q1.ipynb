{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. Recommendation system`\n",
    "`Implementing a recommendation system is critical for businesses and digital platforms that want to thrive in today's competitive environment. These systems use data-driven personalization to tailor content, products, and services to individual user preferences. The latter improves user engagement, satisfaction, retention, and revenue through increased sales and cross-selling opportunities. In this section, you will attempt to implement a recommendation system by identifying similar users' preferences and recommending movies they watch to the study user.`\n",
    "\n",
    "`To be more specific, you will implement your version of the LSH algorithm, which will take as input the user's preferred genre of movies, find the most similar users to this user, and recommend the most watched movies by those who are more similar to the user.`\n",
    "\n",
    "`Data: The data you will be working with can be found here.`\n",
    "\n",
    "`Looking at the data, you can see that there is data available for each user for the movies the user clicked on. Gather the title and genre of the maximum top 10 movies that each user clicked on regarding the number of clicks.`\n",
    "\n",
    "`1.2 Minhash Signatures`\n",
    "`Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.`\n",
    "\n",
    "`Important note: You must write your minhash function from scratch. You are not permitted to use any already implemented hash functions. Read the class materials and, if necessary, conduct an internet search. The description of hash functions in the book may be helpful as a reference.`\n",
    "\n",
    "`1.3 Locality-Sensitive Hashing (LSH)`\n",
    "`Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at most five movies to the user to watch based on the movies clicked by similar users.`\n",
    "\n",
    "`To recommend at most five movies given a user_id, use the following procedure:`\n",
    "\n",
    "`Identify the two most similar users to this user.`\n",
    "`If these two users have any movies in common, recommend those movies based on the total number of clicks by these users.`\n",
    "`If there are no more common movies, try to propose the most clicked movies by the most similar user first, followed by the other user.`\n",
    "`Note: At the end of the process, we expect to see at most five movies recommended to the user.`\n",
    "\n",
    "`Example: assume you've identified user A and B as the most similar users to a single user, and we have the following records on these users:`\n",
    "\n",
    "`User A with 80% similarity`\n",
    "\n",
    "`User B with 50% similarity`\n",
    "\n",
    "`user\tmovie title\t#clicks`\n",
    "\n",
    "`A\tWild Child\t20`\n",
    "\n",
    "`A\tInnocence\t10`\n",
    "\n",
    "`A\tCoin Heist\t2`\n",
    "\n",
    "`B\tInnocence\t30`\n",
    "\n",
    "`B\tCoin Heist\t15`\n",
    "\n",
    "`B\tBefore I Fall\t30`\n",
    "\n",
    "`B\tBeyond Skyline\t8`\n",
    "\n",
    "`B\tThe Amazing Spider-Man\t5`\n",
    "\n",
    "`Recommended movies in order:`\n",
    "\n",
    "`Innocence`\n",
    "\n",
    "`Coin Heist`\n",
    "\n",
    "`Wild Child`\n",
    "\n",
    "`Before I Fall`\n",
    "\n",
    "`Beyond Skyline`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the title and genre of the maximum top 10 movies that each user clicked on regarding the number of clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv('netflix.csv')\n",
    "df = pd.read_csv(\"/Users/petraudovicic/Desktop/adm/adm-hw4/netflix.csv\")\n",
    "\n",
    "def bestmovies(user):\n",
    "    #The dictionary for all users\n",
    "    users_dict = df.groupby('user_id').apply(lambda x: dict(x['movie_id'].value_counts())).to_dict()\n",
    "    #The dictionary for the specified user\n",
    "    topmovies = users_dict.get(user, {})\n",
    "    # Sorting the dictionary by the value in descending order\n",
    "    sorted_topmovies = dict(sorted(topmovies.items(), key=lambda item: item[1], reverse=True))\n",
    "    # Return only the first 10 key-value pairs\n",
    "    return dict(list(sorted_topmovies.items())[:10])\n",
    "\n",
    "def moviegenres(user):\n",
    "    # Creating a dictionary with movie_id as key and genre as value\n",
    "    movie_genre_dict = pd.Series(df.genres.values,index=df.movie_id).to_dict()\n",
    "\n",
    "    top_10_movies = bestmovies(user)\n",
    "\n",
    "    # Create a dictionary with the top 10 movies as keys and their genres as values\n",
    "    moviegenre = {movie: movie_genre_dict[movie] for movie in top_10_movies.keys()}\n",
    "    return moviegenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.2 Minhash Signatures`\n",
    "`Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making list of genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'NOT AVAILABLE', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "# Splitting the genres and expanding them into separate rows\n",
    "s = df_copy['genres'].str.split(',').apply(pd.Series, 1).stack()\n",
    "\n",
    "# Removing whitespaces, dropping duplicates and sorting\n",
    "s.index = s.index.droplevel(-1)\n",
    "s.name = 'genres'\n",
    "del df_copy['genres']\n",
    "df_copy = df_copy.join(s)\n",
    "genres_list = df_copy['genres'].str.strip().drop_duplicates().sort_values().tolist()\n",
    "\n",
    "print(genres_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making whichgenres column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with a list of 27 zeros\n",
    "df['whichgenres'] = [[0]*27 for _ in range(len(df))]\n",
    "\n",
    "# Updating the new column based on the presence of genres\n",
    "for i, genre in enumerate(genres_list):\n",
    "    df.loc[df['genres'].str.contains(genre), 'whichgenres'] = df.loc[df['genres'].str.contains(genre), 'whichgenres'].apply(lambda x: x[:i] + [1] + x[i+1:])\n",
    "\n",
    "# Saving the updated dataframe to a new csv file\n",
    "df.to_csv('Netflix_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1(k):\n",
    "    return (5*k + 3)%97\n",
    "def h2(k):\n",
    "    return(10*k + 3)%97\n",
    "def h3(k):\n",
    "    return(15*k + 3)%97\n",
    "def h4(k):\n",
    "    return(20*k + 3)%97\n",
    "def h5(k):\n",
    "    return(25*k + 3)%97\n",
    "def h6(k):\n",
    "    return(30*k + 3)%97\n",
    "def h7(k):\n",
    "    return(35*k + 3)%97\n",
    "def h8(k):\n",
    "    return(40*k + 3)%97\n",
    "def h9(k):\n",
    "    return(45*k + 3)%97\n",
    "def h10(k):\n",
    "    return(50*k + 3)%97\n",
    "def h11(k):\n",
    "    return(55*k + 3)%97\n",
    "def h12(k):\n",
    "    return(60*k + 3)%97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making additional column with results of hash functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Netflix_updated.csv')\n",
    "# Apply the hash functions to each row number\n",
    "df['hash_results'] = df.index.to_series().apply(lambda x: [h1(x), h2(x), h3(x), h4(x), h5(x), h6(x), h7(x), h8(x), h9(x), h10(x), h11(x), h12(x)])\n",
    "\n",
    "# Overwrite the original CSV file with the updated DataFrame\n",
    "df.to_csv('Netflix_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>release_date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>whichgenres</th>\n",
       "      <th>hash_results</th>\n",
       "      <th>minh_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58773</td>\n",
       "      <td>2017-01-01 01:15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Angus, Thongs and Perfect Snogging</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>26bd5987e8</td>\n",
       "      <td>1dea19f6fe</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[93, 93, 93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58774</td>\n",
       "      <td>2017-01-01 13:56:02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Curse of Sleeping Beauty</td>\n",
       "      <td>Fantasy, Horror, Mystery, Thriller</td>\n",
       "      <td>2016-06-02</td>\n",
       "      <td>f26ed2675e</td>\n",
       "      <td>544dcbc510</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63]</td>\n",
       "      <td>[5, 23, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58775</td>\n",
       "      <td>2017-01-01 15:17:47</td>\n",
       "      <td>10530.0</td>\n",
       "      <td>London Has Fallen</td>\n",
       "      <td>Action, Thriller</td>\n",
       "      <td>2016-03-04</td>\n",
       "      <td>f77e500e7a</td>\n",
       "      <td>7cbcc791bf</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[13, 23, 33, 43, 53, 63, 73, 83, 93, 6, 16, 26]</td>\n",
       "      <td>[5, 41, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58776</td>\n",
       "      <td>2017-01-01 16:04:13</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Vendetta</td>\n",
       "      <td>Action, Drama</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>c74aec7673</td>\n",
       "      <td>ebf43c36b6</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[18, 33, 48, 63, 78, 93, 11, 26, 41, 56, 71, 86]</td>\n",
       "      <td>[23, 7, 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58777</td>\n",
       "      <td>2017-01-01 19:16:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The SpongeBob SquarePants Movie</td>\n",
       "      <td>Animation, Action, Adventure, Comedy, Family, ...</td>\n",
       "      <td>2004-11-19</td>\n",
       "      <td>a80d6fc2aa</td>\n",
       "      <td>a57c992287</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[23, 43, 63, 83, 6, 26, 46, 66, 86, 9, 29, 49]</td>\n",
       "      <td>[14, 7, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             datetime  duration  \\\n",
       "0       58773  2017-01-01 01:15:09       0.0   \n",
       "1       58774  2017-01-01 13:56:02       0.0   \n",
       "2       58775  2017-01-01 15:17:47   10530.0   \n",
       "3       58776  2017-01-01 16:04:13      49.0   \n",
       "4       58777  2017-01-01 19:16:37       0.0   \n",
       "\n",
       "                                title  \\\n",
       "0  Angus, Thongs and Perfect Snogging   \n",
       "1        The Curse of Sleeping Beauty   \n",
       "2                   London Has Fallen   \n",
       "3                            Vendetta   \n",
       "4     The SpongeBob SquarePants Movie   \n",
       "\n",
       "                                              genres release_date    movie_id  \\\n",
       "0                             Comedy, Drama, Romance   2008-07-25  26bd5987e8   \n",
       "1                 Fantasy, Horror, Mystery, Thriller   2016-06-02  f26ed2675e   \n",
       "2                                   Action, Thriller   2016-03-04  f77e500e7a   \n",
       "3                                      Action, Drama   2015-06-12  c74aec7673   \n",
       "4  Animation, Action, Adventure, Comedy, Family, ...   2004-11-19  a80d6fc2aa   \n",
       "\n",
       "      user_id                                        whichgenres  \\\n",
       "0  1dea19f6fe  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  544dcbc510  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...   \n",
       "2  7cbcc791bf  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  ebf43c36b6  [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  a57c992287  [1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                       hash_results  minh_results  \n",
       "0              [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  [93, 93, 93]  \n",
       "1   [8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63]   [5, 23, 41]  \n",
       "2   [13, 23, 33, 43, 53, 63, 73, 83, 93, 6, 16, 26]    [5, 41, 7]  \n",
       "3  [18, 33, 48, 63, 78, 93, 11, 26, 41, 56, 71, 86]   [23, 7, 34]  \n",
       "4    [23, 43, 63, 83, 6, 26, 46, 66, 86, 9, 29, 49]    [14, 7, 0]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your minh function\n",
    "def minh(elements):\n",
    "    return min(h6(x) for x in elements)\n",
    "\n",
    "# Apply the minh function to each subset of 4 elements in the hash_results column\n",
    "df['minh_results'] = df['hash_results'].apply(lambda x: [minh(x[i:i+4]) for i in range(0, len(x), 4)])\n",
    "\n",
    "# Overwrite the original CSV file with the updated DataFrame\n",
    "df.to_csv('Netflix_updated.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that takes a user_id as input and returns user ids of the 2 users that are most similar to the user from the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function that extracts minh_results of the user\n",
    "def users_minh(user_id):\n",
    "    user_data = df[df['user_id'] == user_id].drop_duplicates(subset=['minh_results'])\n",
    "    get_minh_results = user_data['minh_results'].tolist()\n",
    "    \n",
    "    return get_minh_results\n",
    "\n",
    "\n",
    "#a function that represents the similarity between users. it takes the lists with all the minhash scores of the movies they watched and compares them\n",
    "def points(user1, user2):\n",
    "    list1=users_minh(user1)\n",
    "    list2=users_minh(user2)\n",
    "    # Initialize a counter\n",
    "    count = 0\n",
    "    # Iterate over each 'minh' in the first list\n",
    "    for minh1 in list1:\n",
    "        #iterate over each 'minh' in the second list\n",
    "        for minh2 in list2:\n",
    "            #iterate over each element in the list (every element is a list of the size 3)\n",
    "            for i in range(3):\n",
    "                #compare elements on the same position between all lists\n",
    "                if minh1[i] == minh2[i]:\n",
    "                    # If the i-th elements are the same, increment the counter\n",
    "                    count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "#a function that takes a user_id as input and returns the most similar and second most similar user to the one from the input\n",
    "def similar2(user_id):\n",
    "    # Load the data from the CSV file\n",
    "    df = pd.read_csv('Netflix_updated.csv')\n",
    "    \n",
    "    # Get the 'minh_results' for the given user_id\n",
    "    user_minh_results = users_minh(user_id)\n",
    "    \n",
    "    score=dict()\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        score[row['user_id']]=points(user_id, row['user_id'])\n",
    "    sorted_dict = {k: v for k, v in sorted(score.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    return (sorted_dict.keys[0], sorted_dict.keys[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By extracting movies from the two most similar users, the code recommends 5 movies that will user most likely find interesting. First, we made a function that returns all users similar to the user given as an input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function that extracts all similar users of the user\n",
    "def get_matching_users(user_id):\n",
    "    \n",
    "    # extract minh_results of the user\n",
    "    user_data = df[df['user_id'] == user_id].drop_duplicates(subset=['minh_results'])\n",
    "    minh_results = user_data['minh_results'].tolist()\n",
    "    \n",
    "    # extract all movie indices that have at least one similar bucket\n",
    "    matching_movies_indices = df.apply(lambda row: any(all(row['minh_results'][i] == minh_result[i]\n",
    "                                                           for i in range(len(minh_result)))\n",
    "                                                       for minh_result in minh_results), axis=1)\n",
    "    \n",
    "    # extract all movies based on the indices\n",
    "    matching_movies = df[matching_movies_indices]\n",
    "    \n",
    "    # excluding the movies from the own user\n",
    "    matching_movies = matching_movies[matching_movies['user_id'] != user_id]\n",
    "    \n",
    "    # add column with total movies count for every user as a tie breaker\n",
    "    matching_movies['movies_count'] = matching_movies.groupby('user_id')['user_id'].transform('count')\n",
    "    \n",
    "    # create temporary column of minh_results as a string for dropping duplicates\n",
    "    matching_movies['tmp_minh_results'] = matching_movies['minh_results'].apply(lambda x: str(x))\n",
    "    \n",
    "    # extract unique minh_results from every user\n",
    "    matching_users = matching_movies.drop_duplicates(subset=['user_id', 'tmp_minh_results'])\n",
    "    \n",
    "    # drop temporary column again\n",
    "    unique_matching_users = matching_users.drop('tmp_minh_results', axis=1)\n",
    "    \n",
    "    return unique_matching_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding two most similar users, the code extracts all the movies both of them watched. If there are 5 movies like that, these 5 movies will be recommended. If there are less then 5, other movies recommended will be taken on account of the number of clicks the most similar user made. If there are more then 5 movies two most similar users have in common, the 5 out of them will be chosen on account of the number of clicks of the most similar user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_movies(user_id):\n",
    "    # Filter the DataFrame to include only rows where 'user_id' is the input user_id\n",
    "    user_movies = df[df['user_id'] == user_id]\n",
    "\n",
    "    # Get the 'movie_id' column from the filtered DataFrame\n",
    "    movie_ids = user_movies['movie_id']\n",
    "\n",
    "    return movie_ids.tolist()\n",
    "#function that takes a user and returns five movies recommended \n",
    "def rec_movies(user_id):\n",
    "    # extract all similar users of the user\n",
    "    unique_matching_users = get_matching_users(user_id)\n",
    "\n",
    "    # group by user_id and movies_count\n",
    "    unique_matching_users = unique_matching_users.groupby(['user_id', 'movies_count']).agg({'minh_results': 'count'})\n",
    "\n",
    "    # sort by the most unique similar minh_results and use movies_count as tie breaker\n",
    "    similar_users = unique_matching_users.reset_index().sort_values(by=['minh_results', 'movies_count'], ascending=[False, False])\n",
    "    su=list(similar_users['user_id'][0:2])\n",
    "\n",
    "\n",
    "    m1=get_movies(su[0])\n",
    "    m2=get_movies(su[1])\n",
    "    movies=list(set(m1).intersection(set(m2)))\n",
    "    if(len(movies)==5):\n",
    "        return movies\n",
    "    #we have to add movies from the most similar user\n",
    "    if(len(movies)<5):\n",
    "        for i in m1:\n",
    "            if(i in movies):\n",
    "                m1.remove(i) \n",
    "        c=Counter(m1)\n",
    "        a=len(movies) \n",
    "        for i in c.most_common(5-a):\n",
    "            movies.append(i[0])\n",
    "        return movies\n",
    "    #we have to leave top 5 of the most similar user among these movies he has in common with the second most similar\n",
    "    if(len(movies)>5):\n",
    "        for i in m1:\n",
    "            if(i not in movies):\n",
    "                m1.remove(i)\n",
    "        c=Counter(m1)\n",
    "        movies=list()\n",
    "        for i in c.most_common(5):\n",
    "            movies.append(i[0])\n",
    "        return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c424c83faf', '26bb20f603', '4522035263', '36f313b96d', '48bb06427a']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_movies('544dcbc510')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
