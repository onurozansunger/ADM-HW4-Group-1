{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1. Recommendation system`\n",
    "`Implementing a recommendation system is critical for businesses and digital platforms that want to thrive in today's competitive environment. These systems use data-driven personalization to tailor content, products, and services to individual user preferences. The latter improves user engagement, satisfaction, retention, and revenue through increased sales and cross-selling opportunities. In this section, you will attempt to implement a recommendation system by identifying similar users' preferences and recommending movies they watch to the study user.`\n",
    "\n",
    "`To be more specific, you will implement your version of the LSH algorithm, which will take as input the user's preferred genre of movies, find the most similar users to this user, and recommend the most watched movies by those who are more similar to the user.`\n",
    "\n",
    "`Data: The data you will be working with can be found here.`\n",
    "\n",
    "`Looking at the data, you can see that there is data available for each user for the movies the user clicked on. Gather the title and genre of the maximum top 10 movies that each user clicked on regarding the number of clicks.`\n",
    "\n",
    "`1.2 Minhash Signatures`\n",
    "`Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.`\n",
    "\n",
    "`Important note: You must write your minhash function from scratch. You are not permitted to use any already implemented hash functions. Read the class materials and, if necessary, conduct an internet search. The description of hash functions in the book may be helpful as a reference.`\n",
    "\n",
    "`1.3 Locality-Sensitive Hashing (LSH)`\n",
    "`Now that your buckets are ready, it's time to ask a few queries. We will provide you with some user_ids and ask you to recommend at most five movies to the user to watch based on the movies clicked by similar users.`\n",
    "\n",
    "`To recommend at most five movies given a user_id, use the following procedure:`\n",
    "\n",
    "`Identify the two most similar users to this user.`\n",
    "`If these two users have any movies in common, recommend those movies based on the total number of clicks by these users.`\n",
    "`If there are no more common movies, try to propose the most clicked movies by the most similar user first, followed by the other user.`\n",
    "`Note: At the end of the process, we expect to see at most five movies recommended to the user.`\n",
    "\n",
    "`Example: assume you've identified user A and B as the most similar users to a single user, and we have the following records on these users:`\n",
    "\n",
    "`User A with 80% similarity`\n",
    "\n",
    "`User B with 50% similarity`\n",
    "\n",
    "`user\tmovie title\t#clicks`\n",
    "\n",
    "`A\tWild Child\t20`\n",
    "\n",
    "`A\tInnocence\t10`\n",
    "\n",
    "`A\tCoin Heist\t2`\n",
    "\n",
    "`B\tInnocence\t30`\n",
    "\n",
    "`B\tCoin Heist\t15`\n",
    "\n",
    "`B\tBefore I Fall\t30`\n",
    "\n",
    "`B\tBeyond Skyline\t8`\n",
    "\n",
    "`B\tThe Amazing Spider-Man\t5`\n",
    "\n",
    "`Recommended movies in order:`\n",
    "\n",
    "`Innocence`\n",
    "\n",
    "`Coin Heist`\n",
    "\n",
    "`Wild Child`\n",
    "\n",
    "`Before I Fall`\n",
    "\n",
    "`Beyond Skyline`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the title and genre of the maximum top 10 movies that each user clicked on regarding the number of clicks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('netflix.csv')\n",
    "\n",
    "def bestmovies(user):\n",
    "    #The dictionary for all users\n",
    "    users_dict = df.groupby('user_id').apply(lambda x: dict(x['movie_id'].value_counts())).to_dict()\n",
    "    #The dictionary for the specified user\n",
    "    topmovies = users_dict.get(user, {})\n",
    "    # Sorting the dictionary by the value in descending order\n",
    "    sorted_topmovies = dict(sorted(topmovies.items(), key=lambda item: item[1], reverse=True))\n",
    "    # Return only the first 10 key-value pairs\n",
    "    return dict(list(sorted_topmovies.items())[:10])\n",
    "\n",
    "def moviegenres(user):\n",
    "    # Creating a dictionary with movie_id as key and genre as value\n",
    "    movie_genre_dict = pd.Series(df.genres.values,index=df.movie_id).to_dict()\n",
    "\n",
    "    top_10_movies = bestmovies(user)\n",
    "\n",
    "    # Create a dictionary with the top 10 movies as keys and their genres as values\n",
    "    moviegenre = {movie: movie_genre_dict[movie] for movie in top_10_movies.keys()}\n",
    "    return moviegenre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.2 Minhash Signatures`\n",
    "`Using the movie genre and user_ids, try to implement your min-hash signatures so that users with similar interests in a genre appear in the same bucket.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making list of genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Splitting the genres and expanding them into separate rows\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m s \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mgenres\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(pd\u001b[39m.\u001b[39;49mSeries, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mstack()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Removing whitespaces, dropping duplicates and sorting\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m s\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mdroplevel(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1183\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m-> 1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49m_constructor_expanddim(\u001b[39mlist\u001b[39;49m(mapped), index\u001b[39m=\u001b[39;49mobj\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   1184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor(mapped, index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\u001b[39m.\u001b[39m__finalize__(\n\u001b[1;32m   1186\u001b[0m         obj, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1187\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 746\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    747\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    748\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    749\u001b[0m         data,\n\u001b[1;32m    750\u001b[0m         columns,\n\u001b[1;32m    751\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    752\u001b[0m         dtype,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m         arrays,\n\u001b[1;32m    756\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/construction.py:869\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    867\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_dict_to_arrays(data, columns)\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m--> 869\u001b[0m     arr, columns \u001b[39m=\u001b[39m _list_of_series_to_arrays(data, columns)\n\u001b[1;32m    870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[39m# last ditch effort\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/internals/construction.py:912\u001b[0m, in \u001b[0;36m_list_of_series_to_arrays\u001b[0;34m(data, columns)\u001b[0m\n\u001b[1;32m    910\u001b[0m     indexer \u001b[39m=\u001b[39m indexer_cache[\u001b[39mid\u001b[39m(index)]\n\u001b[1;32m    911\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 912\u001b[0m     indexer \u001b[39m=\u001b[39m indexer_cache[\u001b[39mid\u001b[39m(index)] \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_indexer(columns)\n\u001b[1;32m    914\u001b[0m values \u001b[39m=\u001b[39m extract_array(s, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    915\u001b[0m aligned_values\u001b[39m.\u001b[39mappend(algorithms\u001b[39m.\u001b[39mtake_nd(values, indexer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3909\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3906\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3907\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m-> 3909\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_compare(target) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_partial_index(target):\n\u001b[1;32m   3910\u001b[0m     \u001b[39m# IntervalIndex get special treatment bc numeric scalars can be\u001b[39;00m\n\u001b[1;32m   3911\u001b[0m     \u001b[39m#  matched to Interval scalars\u001b[39;00m\n\u001b[1;32m   3912\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_indexer_non_comparable(target, method\u001b[39m=\u001b[39mmethod, unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3914\u001b[0m \u001b[39mif\u001b[39;00m is_categorical_dtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   3915\u001b[0m     \u001b[39m# _maybe_cast_listlike_indexer ensures target has our dtype\u001b[39;00m\n\u001b[1;32m   3916\u001b[0m     \u001b[39m#  (could improve perf by doing _should_compare check earlier?)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:6299\u001b[0m, in \u001b[0;36mIndex._should_compare\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6291\u001b[0m \u001b[39mif\u001b[39;00m (other\u001b[39m.\u001b[39mis_boolean() \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_numeric()) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   6292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_boolean() \u001b[39mand\u001b[39;00m other\u001b[39m.\u001b[39mis_numeric()\n\u001b[1;32m   6293\u001b[0m ):\n\u001b[1;32m   6294\u001b[0m     \u001b[39m# GH#16877 Treat boolean labels passed to a numeric index as not\u001b[39;00m\n\u001b[1;32m   6295\u001b[0m     \u001b[39m#  found. Without this fix False and True would be treated as 0 and 1\u001b[39;00m\n\u001b[1;32m   6296\u001b[0m     \u001b[39m#  respectively.\u001b[39;00m\n\u001b[1;32m   6297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 6299\u001b[0m other \u001b[39m=\u001b[39m unpack_nested_dtype(other)\n\u001b[1;32m   6300\u001b[0m dtype \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   6301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_comparable_dtype(dtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:7470\u001b[0m, in \u001b[0;36munpack_nested_dtype\u001b[0;34m(other)\u001b[0m\n\u001b[1;32m   7457\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7458\u001b[0m \u001b[39mWhen checking if our dtype is comparable with another, we need\u001b[39;00m\n\u001b[1;32m   7459\u001b[0m \u001b[39mto unpack CategoricalDtype to look at its categories.dtype.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7467\u001b[0m \u001b[39mIndex\u001b[39;00m\n\u001b[1;32m   7468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   7469\u001b[0m dtype \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mdtype\n\u001b[0;32m-> 7470\u001b[0m \u001b[39mif\u001b[39;00m is_categorical_dtype(dtype):\n\u001b[1;32m   7471\u001b[0m     \u001b[39m# If there is ever a SparseIndex, this could get dispatched\u001b[39;00m\n\u001b[1;32m   7472\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[1;32m   7473\u001b[0m     \u001b[39m# error: Item  \"dtype[Any]\"/\"ExtensionDtype\" of \"Union[dtype[Any],\u001b[39;00m\n\u001b[1;32m   7474\u001b[0m     \u001b[39m# ExtensionDtype]\" has no attribute \"categories\"\u001b[39;00m\n\u001b[1;32m   7475\u001b[0m     \u001b[39mreturn\u001b[39;00m dtype\u001b[39m.\u001b[39mcategories  \u001b[39m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   7476\u001b[0m \u001b[39mreturn\u001b[39;00m other\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/common.py:534\u001b[0m, in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m arr_or_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[39mreturn\u001b[39;00m CategoricalDtype\u001b[39m.\u001b[39;49mis_dtype(arr_or_dtype)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/base.py:312\u001b[0m, in \u001b[0;36mExtensionDtype.is_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39mCheck if we match 'dtype'.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39m   conditions is true for ``dtype.dtype``.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, dtype)\n\u001b[0;32m--> 312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, (ABCSeries, ABCIndex, ABCDataFrame, np\u001b[39m.\u001b[39mdtype)):\n\u001b[1;32m    313\u001b[0m     \u001b[39m# https://github.com/pandas-dev/pandas/issues/22960\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39m# avoid passing data to `construct_from_string`. This could\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# cause a FutureWarning from numpy about failing elementwise\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# comparison from, e.g., comparing DataFrame == 'category'.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39melif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/generic.py:47\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m@classmethod\u001b[39m  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_instancecheck\u001b[39m(\u001b[39mcls\u001b[39m, inst) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m _check(inst) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inst, \u001b[39mtype\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/dtypes/generic.py:40\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._check\u001b[0;34m(inst)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_pandas_abc_type\u001b[39m(name, attr, comp):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_check\u001b[39m(inst):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(inst, attr, \u001b[39m\"\u001b[39m\u001b[39m_typ\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39min\u001b[39;00m comp\n\u001b[1;32m     43\u001b[0m     \u001b[39m# https://github.com/python/mypy/issues/1006\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# error: 'classmethod' used with a non-method\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the genres and expanding them into separate rows\n",
    "s = df['genres'].str.split(',').apply(pd.Series, 1).stack()\n",
    "\n",
    "# Removing whitespaces, dropping duplicates and sorting\n",
    "s.index = s.index.droplevel(-1)\n",
    "s.name = 'genres'\n",
    "del df['genres']\n",
    "df = df.join(s)\n",
    "genres_list = df['genres'].str.strip().drop_duplicates().sort_values().tolist()\n",
    "\n",
    "print(genres_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making whichgenres column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with a list of 27 zeros\n",
    "df['whichgenres'] = [[0]*27 for _ in range(len(df))]\n",
    "\n",
    "# Updating the new column based on the presence of genres\n",
    "for i, genre in enumerate(genres_list):\n",
    "    df.loc[df['genres'].str.contains(genre), 'whichgenres'] = df.loc[df['genres'].str.contains(genre), 'whichgenres'].apply(lambda x: x[:i] + [1] + x[i+1:])\n",
    "\n",
    "# Saving the updated dataframe to a new csv file\n",
    "df.to_csv('Netflix_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h1(k):\n",
    "    return (5*k + 3)%97\n",
    "def h2(k):\n",
    "    return(10*k + 3)%97\n",
    "def h3(k):\n",
    "    return(15*k + 3)%97\n",
    "def h4(k):\n",
    "    return(20*k + 3)%97\n",
    "def h5(k):\n",
    "    return(25*k + 3)%97\n",
    "def h6(k):\n",
    "    return(30*k + 3)%97\n",
    "def h7(k):\n",
    "    return(35*k + 3)%97\n",
    "def h8(k):\n",
    "    return(40*k + 3)%97\n",
    "def h9(k):\n",
    "    return(45*k + 3)%97\n",
    "def h10(k):\n",
    "    return(50*k + 3)%97\n",
    "def h11(k):\n",
    "    return(55*k + 3)%97\n",
    "def h12(k):\n",
    "    return(60*k + 3)%97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making additional column with results of hash functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Netflix_updated.csv')\n",
    "# Apply the hash functions to each row number\n",
    "df['hash_results'] = df.index.to_series().apply(lambda x: [h1(x), h2(x), h3(x), h4(x), h5(x), h6(x), h7(x), h8(x), h9(x), h10(x), h11(x), h12(x)])\n",
    "\n",
    "# Overwrite the original CSV file with the updated DataFrame\n",
    "df.to_csv('Netflix_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0             datetime  duration  \\\n",
      "0       58773  2017-01-01 01:15:09       0.0   \n",
      "1       58773  2017-01-01 01:15:09       0.0   \n",
      "2       58773  2017-01-01 01:15:09       0.0   \n",
      "3       58774  2017-01-01 13:56:02       0.0   \n",
      "4       58774  2017-01-01 13:56:02       0.0   \n",
      "\n",
      "                                title release_date    movie_id     user_id  \\\n",
      "0  Angus, Thongs and Perfect Snogging   2008-07-25  26bd5987e8  1dea19f6fe   \n",
      "1  Angus, Thongs and Perfect Snogging   2008-07-25  26bd5987e8  1dea19f6fe   \n",
      "2  Angus, Thongs and Perfect Snogging   2008-07-25  26bd5987e8  1dea19f6fe   \n",
      "3        The Curse of Sleeping Beauty   2016-06-02  f26ed2675e  544dcbc510   \n",
      "4        The Curse of Sleeping Beauty   2016-06-02  f26ed2675e  544dcbc510   \n",
      "\n",
      "     genres                                        whichgenres  \\\n",
      "0    Comedy  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1     Drama  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2   Romance  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3   Fantasy  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
      "4    Horror  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
      "\n",
      "                                       hash_results  minh_results  \n",
      "0              [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  [93, 93, 93]  \n",
      "1   [8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63]   [5, 23, 41]  \n",
      "2   [13, 23, 33, 43, 53, 63, 73, 83, 93, 6, 16, 26]    [5, 41, 7]  \n",
      "3  [18, 33, 48, 63, 78, 93, 11, 26, 41, 56, 71, 86]   [23, 7, 34]  \n",
      "4    [23, 43, 63, 83, 6, 26, 46, 66, 86, 9, 29, 49]    [14, 7, 0]  \n"
     ]
    }
   ],
   "source": [
    "# Define your minh function\n",
    "def minh(elements):\n",
    "    return min(h6(x) for x in elements)\n",
    "\n",
    "# Apply the minh function to each subset of 4 elements in the hash_results column\n",
    "df['minh_results'] = df['hash_results'].apply(lambda x: [minh(x[i:i+4]) for i in range(0, len(x), 4)])\n",
    "\n",
    "# Overwrite the original CSV file with the updated DataFrame\n",
    "df.to_csv('Netflix_updated.csv', index=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that takes a user_id as input and returns user ids of the 2 users that are most similar to the user from the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create dictionaries to map user_ids and movie_ids to their minh_results\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m user_minh_dict \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mminh_results\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m movie_minh_dict \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mmovie_id\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mminh_results\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39musers_minh\u001b[39m(user_id):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create dictionaries to map user_ids and movie_ids to their minh_results\n",
    "user_minh_dict = df.set_index('user_id')['minh_results'].to_dict()\n",
    "movie_minh_dict = df.set_index('movie_id')['minh_results'].to_dict()\n",
    "\n",
    "def users_minh(user_id):\n",
    "    return user_minh_dict.get(user_id, [])\n",
    "\n",
    "def movies_minh(movie_id):\n",
    "    return movie_minh_dict.get(movie_id, [])\n",
    "\n",
    "def points(list1, list2):\n",
    "    # Flatten the lists\n",
    "    flat_list1 = [item for sublist in list1 for item in sublist]\n",
    "    flat_list2 = [item for sublist in list2 for item in sublist]\n",
    "    \n",
    "    # Compare the flattened lists\n",
    "    count = sum(a == b for a, b in zip(flat_list1, flat_list2))\n",
    "    return count\n",
    "\n",
    "def movies_concerned(user_id):\n",
    "    user_minh_results = users_minh(user_id)\n",
    "    concerned_movie_ids = []\n",
    "    \n",
    "    for movie_id, movie_minh_results in movie_minh_dict.items():\n",
    "        if points(user_minh_results, movie_minh_results) > 0:\n",
    "            concerned_movie_ids.append(movie_id)\n",
    "    \n",
    "    return concerned_movie_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies_concerned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb15926c011\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petraudovicic/Desktop/adm/adm-hw4/Untitled-1.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(movies_concerned(user_id))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movies_concerned' is not defined"
     ]
    }
   ],
   "source": [
    "user_id = \"b15926c011\"\n",
    "print(movies_concerned(user_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
